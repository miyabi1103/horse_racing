
import create_population

import preprocessing_nar
from feature_engineering import FeatureCreator



import pandas as pd





from train_lightgbm_time import Trainer_lightgbm_time
from train_lgbm_time_cross import Trainer_lightgbm_time_cv

from evaluation_lightgbm_time_kaiki import Evaluator_lightgbm_time_kaiki

from evaluation_shaft_time_kaiki_cross import Evaluator_lightgbm_time_kaiki_shaft

import json
from pathlib import Path


import re

import pandas as pd
import numpy as np
import ast

from pathlib import Path

COMMON_DATA_DIR = Path("..", "..","..",  "common_nar", "data_nar")
POPULATION_DIR_NEW = COMMON_DATA_DIR / "prediction_population"
%load_ext autoreload


%autoreload


pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)


import asyncio
import re
from playwright.async_api import Playwright, async_playwright, expect
import pandas as pd
from io import StringIO


import asyncio
import re
from playwright.async_api import Playwright, async_playwright, expect
import pandas as pd
from io import StringIO
from collections import defaultdict
from bs4 import BeautifulSoup
import numpy as np
import ast

import sys
from pathlib import Path


import matplotlib
matplotlib.use("Agg")  # GUIバックエンドを無効化
import matplotlib.pyplot as plt

DATA_DIR = Path("..", "..", "data_nar")
SAVE_DIR = DATA_DIR / "05_prediction_results"
from dotenv import load_dotenv
# .envファイルを読み込む
load_dotenv()
import os
# DiscordのWebhook URLを環境変数から取得
SPAT_KANYUSYA_URL = os.getenv("SPAT_KANYUSYA_NUM")
USE_URL = os.getenv("USER_ID")
PASSWORD = os.getenv("SPAT_PASSWORD")


await context.close()



await browser.close()


    await context.close()
    await browser.close()


!playwright codegen --target python-async https://www.spat4.jp/keiba/pc





import asyncio
import re
from playwright.async_api import Playwright, async_playwright, expect

playwright = await async_playwright().start()


browser = await playwright.chromium.launch(headless=False)


context = await browser.new_context()


page = await context.new_page()
await page.goto("https://www.spat4.jp/keiba/pc")


    place_mapping = {
        30: "門別",
        35: "盛岡",
        36: "水沢",
        42: "浦和",
        43: "船橋",
        44: "大井",
        45: "川崎",
        46: "金沢",
        47: "笠松",
        48: "名古屋",
        50: "園田",
        51: "姫路",
        54: "高知",
        55: "佐賀"
    }

race_id = "202545040911"
place_name = f"{place_mapping[int(race_id[4:6])]}"
place_count = f"{int(race_id[10:12])}"



        await page.locator("#MEMBERNUMR").click()
        await page.locator("#MEMBERNUMR").fill(SPAT_KANYUSYA_URL)
        await page.locator("#MEMBERIDR").click()
        await page.locator("#MEMBERIDR").fill(USE_URL)
        await page.get_by_text("ログイン", exact=True).click()


        await page.get_by_role("link", name=f"{place_count}R").click()
        async with page.expect_popup() as page2_info:
            await page.get_by_role("button", name="マークカード投票").click()
        page2 = await page2_info.value
        await page2.get_by_text("ボックス").click()
        await page2.get_by_text("馬複").click()


        await page2.get_by_role("button", name=first_umaban, exact=True).click()
        await page2.get_by_role("button", name=second_umaban, exact=True).click()











import asyncio
import re
from playwright.async_api import Playwright, async_playwright, expect

place_mapping = {
    30: "門別",
    35: "盛岡",
    36: "水沢",
    42: "浦和",
    43: "船橋",
    44: "大井",
    45: "川崎",
    46: "金沢",
    47: "笠松",
    48: "名古屋",
    50: "園田",
    51: "姫路",
    54: "高知",
    55: "佐賀"
}
race_id = "202545040810"
async with async_playwright() as playwright:
    # playwright = await async_playwright().start()
    browser = await playwright.chromium.launch(headless=False)
    context = await browser.new_context()
    page = await context.new_page()
    place_name = f"{place_mapping[int(race_id[4:6])]}"
    place_count = f"{int(race_id[10:12])}"

    await page.goto("https://www.spat4.jp/keiba/pc")
    await page.locator("#MEMBERNUMR").click()
    await page.locator("#MEMBERNUMR").fill(SPAT_KANYUSYA_URL)
    await page.locator("#MEMBERIDR").click()
    await page.locator("#MEMBERIDR").fill(USE_URL)
    await page.get_by_text("ログイン", exact=True).click()

    try:
        # ここでplace_countRをクリック（一定時間だけ待つ）
        await asyncio.wait_for(
            page.get_by_role("link", name=place_name, exact=True).click(),
            timeout=10  # 秒
        )
    except asyncio.TimeoutError:
        # タイムアウトしたら代わりに「照会」と「開催要領」ボタンをクリック
        await page.get_by_role("button", name="照会").click()
        await page.get_by_role("button", name="開催要領").click()
    # await page.get_by_role("link", name=f"{place_count}R").click()

    # async with page.expect_popup() as page2_info:
    #     await page.get_by_role("button", name="マークカード投票").click()
    # page2 = await page2_info.value
    # ---------------------
#     await context.close()
#     await browser.close()


# async def main() -> None:
#     async with async_playwright() as playwright:
#         await run(playwright)




await page2.get_by_text("投票する").click()



    await page2.get_by_text("ボックス").click()
    await page2.get_by_text("馬複").click()
    await page2.get_by_role("button", name=2, exact=True).click()
    await page2.get_by_role("button", name=2, exact=True).click()
    await page2.get_by_text("投票金額入力へ").click()
    await page2.get_by_role("cell", name="各 00円 0円").get_by_role("textbox").click()
    await page2.get_by_role("cell", name="各 00円 0円").get_by_role("textbox").fill(1)
    await page2.locator("#gotoCfm-buy").click()
    await page2.locator("input[name=\"cfm_ansho\"]").click()
    await page2.locator("input[name=\"cfm_ansho\"]").fill(PASSWORD)
    await page2.locator("input[name=\"cfm_amount\"]").click()
    await page2.locator("input[name=\"cfm_amount\"]").fill(100)



import asyncio
import re
from playwright.async_api import Playwright, async_playwright, expect

playwright = await async_playwright().start()


browser = await playwright.chromium.launch(headless=False)


context = await browser.new_context()


page = await context.new_page()
await page.goto("https://www.spat4.jp/keiba/pc")


place_name = f"{place_mapping[int(race_id[4:6])]}"
place_count = f"{int(race_id[10:12])}"
await page.locator("#MEMBERNUMR").click()
await page.locator("#MEMBERNUMR").fill(SPAT_KANYUSYA_URL)
await page.locator("#MEMBERIDR").click()
await page.locator("#MEMBERIDR").fill(USE_URL)



await page.get_by_text("ログイン", exact=True).click()



try:
    # ここでplace_countRをクリック（一定時間だけ待つ）
    await asyncio.wait_for(
        page.get_by_role("link", name=place_name, exact=True).click(),
        timeout=10  # 秒
    )
except asyncio.TimeoutError:
    # タイムアウトしたら代わりに「照会」と「開催要領」ボタンをクリック
    await page.get_by_role("button", name="照会").click()
    # await page.get_by_role("button", name="開催要領").click()


await page.get_by_role("link", name=place_name, exact=True).click()


await page.get_by_role("link", name=f"{place_count}R").click()


async with page.expect_popup() as page2_info:
    await page.get_by_role("button", name="マークカード投票").click()
page2 = await page2_info.value



    await page2.get_by_text("ボックス").click()
    await page2.get_by_text("馬複").click()
    await page2.get_by_role("button", name=2, exact=True).click()
    await page2.get_by_role("button", name=2, exact=True).click()
    await page2.get_by_text("投票金額入力へ").click()
    await page2.get_by_role("cell", name="各 00円 0円").get_by_role("textbox").click()
    await page2.get_by_role("cell", name="各 00円 0円").get_by_role("textbox").fill(1)





await page.get_by_role("link", name=place_name, exact=True).click()





















!playwright codegen --target python-async https://www.keiba.go.jp/KeibaWeb/TodayRaceInfo/TodayRaceInfoTop


import asyncio
import re
from playwright.async_api import Playwright, async_playwright, expect
race_id="202548040811" 
place_mapping = {
        1: '札幌',
        2: '函館',
        3: '福島',
        4: '新潟',
        5: '東京',
        6: '中山',
        7: '中京',
        8: '京都',
        9: '阪神',
        10: '小倉',
        30: "門別",
        35: "盛岡",
        36: "水沢",
        42: "浦和",
        43: "船橋",
        44: "大井",
        45: "川崎",
        46: "金沢",
        47: "笠松",
        48: "名古屋",
        50: "園田",
        51: "姫路",
        54: "高知",
        55: "佐賀"

    }
async def run(playwright: Playwright) -> None:
    place_count = f"{int(race_id[10:12])}"
    place_name = f"{place_mapping[int(race_id[4:6])]}"
    browser = await playwright.chromium.launch(headless=False)
    context = await browser.new_context()
    page = await context.new_page()
    await page.goto("https://www.keiba.go.jp/KeibaWeb/TodayRaceInfo/TodayRaceInfoTop")
    await page.get_by_role("link", name=place_name).nth(2).click()
    async with page.expect_navigation():
        # await page.get_by_role("row", name="1R 14:15 Ｃ３三 左1200m 晴 重 12").get_by_role("link").nth(1).click()
        await page.locator("tr").filter(has_text=re.compile(fr"\b{place_count}R\b")).locator("a").nth(1).click()
        # ページ内のリンクテキストをすべて取得して、何があるのか確認する
    html = await page.content()
    html = StringIO(html)
    odds = (
        pd.read_html(html)[0][["馬番","単勝 オッズ"]]
        .set_index("馬番")["単勝 オッズ"]
        .to_dict()
    )
    # ---------------------
    await context.close()
    await browser.close()
    return odds

# async def main() -> None:
async with async_playwright() as playwright:
    odds = await run(playwright)


# asyncio.run(main())



odds





import asyncio
import re
from playwright.async_api import Playwright, async_playwright, expect

playwright = await async_playwright().start()


browser = await playwright.chromium.launch(headless=False)


context = await browser.new_context()


page = await context.new_page()
await page.goto("https://www.keiba.go.jp/KeibaWeb/TodayRaceInfo/TodayRaceInfoTop")


await page.get_by_role("link", name="名古屋").nth(2).click()


await page.get_by_role("row", name="1R 14:15 Ｃ３三 左1200m 晴 重 12").get_by_role("link").nth(1).click()


html = await page.content()
html = StringIO(html)


pd.read_html(html)[0]


    await context.close()
    await browser.close()

















COMMON_DATA_DIR = Path("..", "..", "common", "data")
RAWDF_DIR = COMMON_DATA_DIR / "rawdf"
MAPPING_DIR = COMMON_DATA_DIR / "mapping"
POPULATION_DIR = Path("..", "data", "00_population")
OUTPUT_DIR = Path("..", "data", "01_preprocessed")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)


POPULATION_DIR_NEW = COMMON_DATA_DIR / "prediction_population"

# カテゴリ変数を数値に変換するためのマッピング
with open(MAPPING_DIR / "sex.json", "r") as f:
    sex_mapping = json.load(f)
with open(MAPPING_DIR / "race_type.json", "r") as f:
    race_type_mapping = json.load(f)
with open(MAPPING_DIR / "around.json", "r") as f:
    around_mapping = json.load(f)
with open(MAPPING_DIR / "weather.json", "r") as f:
    weather_mapping = json.load(f)
with open(MAPPING_DIR / "ground_state.json", "r") as f:
    ground_state_mapping = json.load(f)
with open(MAPPING_DIR / "race_class.json", "r") as f:
    race_class_mapping = json.load(f)
with open(MAPPING_DIR / "place.json", "r") as f:
    place_mapping = json.load(f)
populaton_filename = "population_turf.csv"
    
population_dir = POPULATION_DIR
input_dir = RAWDF_DIR
output_dir = OUTPUT_DIR
input_filename = "race_info.csv"
output_filename = "race_info.csv"
race_type_mapping = race_type_mapping
around_mapping = around_mapping
weather_mapping = weather_mapping
ground_state_mapping = ground_state_mapping
race_class_mapping = race_class_mapping


population = pd.read_csv(population_dir / populaton_filename, sep="\t")

# df = pd.read_csv(input_dir / input_filename, sep="\t").query(
#     "race_id in @population['race_id']"
# )
# `race_id`のリストを作成
population_race_ids = population['race_id'].tolist()

# クエリでリストを直接使用
df = pd.read_csv(input_dir / input_filename, sep="\t").query(
    "race_id in @population_race_ids"
)

df



# evalで文字列型の列をリスト型に変換し、一時的な列を作成
df["tmp"] = df["info1"].map(lambda x: eval(x)[0])

# info1 列からコースの長さを取り出して tmp 列を作成
df["tmp2"] = df["info1"].map(lambda x: ast.literal_eval(x))

# tmp 列から距離の部分を抽出
def extract_course_len(info_list):
    for item in info_list:
        match = re.search(r"(\d+)m", item)
        if match:
            return match.group(1)  # マッチした数字部分を返す
    return None  # 該当がなければ None を返す

# コース長を新しい列に追加
df["course_len_1"] = df["tmp2"].apply(extract_course_len)
df["course_len_2"] = df["tmp2"].map(lambda x: x[1]).str.extract(r"(\d+)")
df["combined_course_len"] = df["course_len_1"].fillna(df["course_len_2"])


# ダートor芝or障害
df["race_type"] = df["tmp"].str[0].map(race_type_mapping)

# 右or左or直線
df["around"] = df["tmp"].str[1].map(around_mapping)

# 条件に基づいて course_type を設定
df["course_len_type"] = df["tmp"].apply(
    lambda x: 1 if "内" in str(x[2:3]) else 2 if "外" in str(x[2:3]) else 1
)

df["course_len"] = df["course_len_1"].fillna(df["course_len_2"])
# df["course_len"] = df["tmp"].str.extract(r"(\d+)")
# df["course_len"] = df["tmp"].str.extract(r"(\d+)(?=m)")


df["weather"] = df["info1"].str.extract(r"天候:(\w+)")[0].map(weather_mapping)
df["ground_state"] = (
    df["info1"].str.extract(r"(芝|ダート|障害):(\w+)")[1].map(ground_state_mapping)
)
df["date"] = pd.to_datetime(
    df["info2"].map(lambda x: eval(x)[0]), format="%Y年%m月%d日"
)
regex_race_class = "|".join(race_class_mapping)
df["race_class"] = (
    df["title"]
    .str.extract(rf"({regex_race_class})")
    # タイトルからレース階級情報が取れない場合はinfo2から取得
    .fillna(df["info2"].str.extract(rf"({regex_race_class})"))[0]
    .map(race_class_mapping)
)
df["place"] = df["race_id"].astype(str).str[4:6].astype(int)
df.dropna(subset=["place"], inplace=True)

df["course_type"] = df["place"].astype(str) + df["course_len"].astype(str) + df["course_len_type"].astype(str)


# 年、月、日をそれぞれ抽出
df["date_year"] = df["date"].dt.year
df["date_month"] = df["date"].dt.month
df["date_day"] = df["date"].dt.day


df















